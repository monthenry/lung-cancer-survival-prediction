{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data and prepare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/synthetic_data_lung_cancer.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['DIED'] = 0\n",
    "\n",
    "# Identify rows where the \"death\" state is present\n",
    "death_rows = df[df['DEFINITION_ID'].str.lower() == 'death']\n",
    "\n",
    "# Iterate through each death row and update DIED column for corresponding rows\n",
    "for _, death_row in death_rows.iterrows():\n",
    "    patient_id = death_row['SUBJECT_ID']\n",
    "    death_time = death_row['TIME']\n",
    "    \n",
    "    if death_time < 5:\n",
    "        # Update DIED to 1 for rows with the same PATIENT_ID and TIME within 1 year\n",
    "        df.loc[(df['SUBJECT_ID'] == patient_id), 'DIED'] = 1\n",
    "\n",
    "# Delete death rows\n",
    "df = df[df['DEFINITION_ID'].str.lower() != 'death']\n",
    "df= df.drop(['TIME'], axis=1)\n",
    "\n",
    "# One-hot encode the original DataFrame\n",
    "df = pd.get_dummies(df, columns=['DEFINITION_ID'], prefix='DEF')\n",
    "\n",
    "# Group by 'SUBJECT_ID' and perform a logical OR on 'DIED'\n",
    "df = df.groupby('SUBJECT_ID').max()\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(['DIED'], axis=1)\n",
    "y = df['DIED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our context and requirements, here are several models that we can consider for our binary classification problem in the medical field:\n",
    "\n",
    "Logistic Regression:  \n",
    "* Simple yet effective, especially for binary classification problems.\n",
    "* Provides interpretable coefficients.\n",
    "* Fast to train and suitable for your dataset size.  \n",
    "  \n",
    "Random Forest:  \n",
    "* Ensemble model that can handle both numerical and categorical features.\n",
    "* Robust and less prone to overfitting.\n",
    "* Can provide feature importances.  \n",
    "  \n",
    "Gradient Boosting (e.g., XGBoost):  \n",
    "* Ensemble model known for high performance.\n",
    "* Handles complex relationships well.\n",
    "* Can provide feature importances.  \n",
    "  \n",
    "Support Vector Machines (SVM):  \n",
    "* Suitable for binary classification.\n",
    "* Effective in high-dimensional spaces.\n",
    "* Kernel trick can capture complex relationships.  \n",
    "  \n",
    "Naive Bayes:  \n",
    "* Simple probabilistic model that can work well with sparse, high-dimensional data.\n",
    "* Assumes independence between features.  \n",
    "  \n",
    "Neural Networks:  \n",
    "* Deep learning models can capture complex patterns.\n",
    "* May require more data and computational resources.\n",
    "* Can be effective for feature learning.\n",
    "\n",
    "Given the nature of our data and the problem, starting with Logistic Regression, Random Forest, and XGBoost seems to be a good start. These models cover a range of complexities, and we can evaluate their performance using cross-validation and metrics such as AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUC-ROC: 0.82577379231791\n",
      "Random Forest AUC-ROC: 0.862573361654244\n",
      "XGBoost AUC-ROC: 0.8633256681050799\n",
      "Gradient Boosting AUC-ROC: 0.8681618378309555\n",
      "SVM Cross-Validation AUC-ROC: 0.8453044239808947\n",
      "Naive Bayes Cross-Validation AUC-ROC: 0.7835459337297573\n",
      "Neural Network Cross-Validation AUC-ROC: 0.822034090048796\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr_scores = cross_val_score(lr, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf_scores = cross_val_score(rf, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb_scores = cross_val_score(xgb, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier()\n",
    "gb_scores = cross_val_score(gb, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "svm = SVC(probability=True)\n",
    "svm_scores = cross_val_score(svm, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Naive Bayes\n",
    "nb = BernoulliNB()\n",
    "nb_scores = cross_val_score(nb, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Neural Network\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "nn_scores = cross_val_score(nn, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Print AUC-ROC scores for comparison\n",
    "print(\"Logistic Regression AUC-ROC:\", lr_scores.mean())\n",
    "print(\"Random Forest AUC-ROC:\", rf_scores.mean())\n",
    "print(\"XGBoost AUC-ROC:\", xgb_scores.mean())\n",
    "print(\"Gradient Boosting AUC-ROC:\", gb_scores.mean())\n",
    "print(\"SVM Cross-Validation AUC-ROC:\", np.mean(svm_scores))\n",
    "print(\"Naive Bayes Cross-Validation AUC-ROC:\", np.mean(nb_scores))\n",
    "print(\"Neural Network Cross-Validation AUC-ROC:\", np.mean(nn_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the AUC-ROC scores we obtain, we can see:\n",
    "* Gradient Boosting: Achieves the highest AUC-ROC score (0.8682), indicating good discriminatory power. This model seems promising.\n",
    "* XGBoost: Performs well with an AUC-ROC score of 0.8633. Similar to Gradient Boosting, XGBoost is an ensemble method known for its effectiveness.\n",
    "* Random Forest: Also performs well with an AUC-ROC score of 0.8602. Random Forest is another ensemble method that tends to handle complex relationships.\n",
    "* SVM: Achieves a respectable AUC-ROC score of 0.8453. SVMs are known for their effectiveness in high-dimensional spaces.\n",
    "* Logistic Regression: Provides a decent AUC-ROC score of 0.8258. Logistic Regression is a simple yet effective model.\n",
    "* Neural Network: Shows a reasonable AUC-ROC score of 0.8220. Neural Networks have the potential to capture complex patterns.\n",
    "* Naive Bayes: Achieves the lowest AUC-ROC score of 0.7835. Naive Bayes might be less suitable for this specific problem or could benefit from further tuning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Gradient Boosting: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}\n",
      "Best Hyperparameters for XGBoost: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best Hyperparameters for Random Forest: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Hyperparameters for SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# GRADIENT BoOSTING\n",
    "# Define the parameter grid\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Create the Gradient Boosting model\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_gb = GridSearchCV(gb, param_grid_gb, cv=5, scoring='roc_auc')\n",
    "grid_search_gb.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for Gradient Boosting:\", grid_search_gb.best_params_)\n",
    "\n",
    "# XGBOOST\n",
    "# Define the parameter grid\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_xgb = GridSearchCV(xgb, param_grid_xgb, cv=5, scoring='roc_auc')\n",
    "grid_search_xgb.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for XGBoost:\", grid_search_xgb.best_params_)\n",
    "\n",
    "# RANDOM FOREST\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='roc_auc')\n",
    "grid_search_rf.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "\n",
    "# SVM\n",
    "# Define the parameter grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Create the SVM model\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=5, scoring='roc_auc')\n",
    "grid_search_svm.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters for Gradient Boosting: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}  \n",
    "Best Hyperparameters for XGBoost: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}  \n",
    "Best Hyperparameters for Random Forest: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 200}  \n",
    "Best Hyperparameters for SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model and computing roc_auc scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting AUC-ROC on Test Set: 0.8608265027322405\n",
      "XGBoost AUC-ROC on Test Set: 0.8609972677595628\n",
      "Random Forest AUC-ROC on Test Set: 0.8551912568306012\n",
      "SVM AUC-ROC on Test Set: 0.832308743169399\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(learning_rate=0.05, max_depth=5, n_estimators=100)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict_proba(X_test)[:, 1]\n",
    "auc_gb = roc_auc_score(y_test, y_pred_gb)\n",
    "print(\"Gradient Boosting AUC-ROC on Test Set:\", auc_gb)\n",
    "\n",
    "# Model Evaluation Metrics\n",
    "print(\"\\nGradient Boosting Model Evaluation:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, gb.predict(X_test)))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, gb.predict(X_test)))\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(learning_rate=0.2, max_depth=5, n_estimators=200)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "auc_xgb = roc_auc_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost AUC-ROC on Test Set:\", auc_xgb)\n",
    "\n",
    "# Model Evaluation Metrics\n",
    "print(\"\\nXGBoost Model Evaluation:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb.predict(X_test)))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, xgb.predict(X_test)))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(max_depth=20, min_samples_split=5, n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest AUC-ROC on Test Set:\", auc_rf)\n",
    "\n",
    "# Model Evaluation Metrics\n",
    "print(\"\\nRandom Forest Model Evaluation:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf.predict(X_test)))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf.predict(X_test)))\n",
    "\n",
    "# SVM\n",
    "svm = SVC(C=0.1, gamma='scale', kernel='rbf', probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict_proba(X_test)[:, 1]\n",
    "auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "print(\"\\nSVM AUC-ROC on Test Set:\", auc_svm)\n",
    "\n",
    "# Model Evaluation Metrics\n",
    "print(\"\\nSVM Model Evaluation:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm.predict(X_test)))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use an ensemble of our top performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble AUC-ROC on Test Set: 0.8705601092896175\n"
     ]
    }
   ],
   "source": [
    "# Initialize individual models\n",
    "gb = GradientBoostingClassifier(learning_rate=0.05, max_depth=5, n_estimators=100)\n",
    "xgb = XGBClassifier(learning_rate=0.2, max_depth=5, n_estimators=200)\n",
    "rf = RandomForestClassifier(max_depth=20, min_samples_split=5, n_estimators=200)\n",
    "svm = SVC(C=0.1, gamma='scale', kernel='rbf', probability=True)\n",
    "\n",
    "# Create an ensemble using VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('gb', gb),\n",
    "    ('xgb', xgb),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm)\n",
    "], voting='soft')  # 'soft' for averaging predicted probabilities\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_ensemble = ensemble.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate AUC-ROC on the test set\n",
    "auc_ensemble = roc_auc_score(y_test, y_pred_ensemble)\n",
    "print(\"Ensemble AUC-ROC on Test Set:\", auc_ensemble)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
